{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": "import nltk\nfrom nltk.stem import PorterStemmer"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "vector\navoid\nintent\nbook\npen\ngood\ndive\nswim\nswim\nrun\ncare\n\nran\ntabl\nbottl\ndemonet\namaz\nhappi\nlazi\nunintent\nnation\nambigu\ndanc\ndanc\nbadli\nfocibl\n"
    }
   ],
   "source": "stemmerporter = PorterStemmer()\n# Works Fine\nprint(stemmerporter.stem('vectorization'))\nprint(stemmerporter.stem('avoidable'))\nprint(stemmerporter.stem('intentional'))\nprint(stemmerporter.stem('books'))\nprint(stemmerporter.stem('pens'))\nprint(stemmerporter.stem('goods'))\nprint(stemmerporter.stem('dives'))\nprint(stemmerporter.stem('swims'))\nprint(stemmerporter.stem('swimming'))\nprint(stemmerporter.stem('running'))\nprint(stemmerporter.stem('caring'))\n\nprint\n# Doesn't work\nprint(stemmerporter.stem('ran'))\nprint(stemmerporter.stem('tables'))\nprint(stemmerporter.stem('bottles'))\nprint(stemmerporter.stem('demonetization'))\nprint(stemmerporter.stem('amazing'))\nprint(stemmerporter.stem('happiness'))\nprint(stemmerporter.stem('laziness'))\nprint(stemmerporter.stem('unintentional'))\nprint(stemmerporter.stem('national'))\nprint(stemmerporter.stem('ambiguous'))\nprint(stemmerporter.stem('dancing'))\nprint(stemmerporter.stem('dances'))\nprint(stemmerporter.stem('badly'))\nprint(stemmerporter.stem('focible'))"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": "from nltk.stem import SnowballStemmer"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "vector\navoid\nintent\nbook\npen\ngood\ndive\nswim\nswim\nrun\ncare\nbad\n\nran\ntabl\nbottl\ndemonet\namaz\nhappi\nlazi\nunintent\nnation\nambigu\ndanc\ndanc\nfocibl\n"
    }
   ],
   "source": "stemmersnow = SnowballStemmer('english')\n\n# Works Fine\nprint(stemmersnow.stem('vectorization'))\nprint(stemmersnow.stem('avoidable'))\nprint(stemmersnow.stem('intentional'))\nprint(stemmersnow.stem('books'))\nprint(stemmersnow.stem('pens'))\nprint(stemmersnow.stem('goods'))\nprint(stemmersnow.stem('dives'))\nprint(stemmersnow.stem('swims'))\nprint(stemmersnow.stem('swimming'))\nprint(stemmersnow.stem('running'))\nprint(stemmersnow.stem('caring'))\nprint(stemmersnow.stem('badly'))\n\nprint\n# Doesn't work\nprint(stemmersnow.stem('ran'))\nprint(stemmersnow.stem('tables'))\nprint(stemmersnow.stem('bottles'))\nprint(stemmersnow.stem('demonetization'))\nprint(stemmersnow.stem('amazing'))\nprint(stemmersnow.stem('happiness'))\nprint(stemmersnow.stem('laziness'))\nprint(stemmersnow.stem('unintentional'))\nprint(stemmersnow.stem('national'))\nprint(stemmersnow.stem('ambiguous'))\nprint(stemmersnow.stem('dancing'))\nprint(stemmersnow.stem('dances'))\nprint(stemmersnow.stem('focible'))"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "16\n(u'arabic', u'danish', u'dutch', u'english', u'finnish', u'french', u'german', u'hungarian', u'italian', u'norwegian', u'porter', u'portuguese', u'romanian', u'russian', u'spanish', u'swedish')\n"
    }
   ],
   "source": "print(len(SnowballStemmer.languages))\nprint(SnowballStemmer.languages)"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": "# New Stemmers\nfrom nltk.stem import RSLPStemmer\nfrom nltk.stem import ISRIStemmer"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "intent\nbook\npem\ngood\ndiv\nswim\n\ncaring\nbadly\nswimming\nrunning\navoidabl\nvectorization\nran\ntabl\nbottl\ndemonetization\namazing\nhappines\nlazines\nunintent\nnation\nambigu\ndancing\ndanc\nfocibl\n"
    }
   ],
   "source": "stemmerrslps = RSLPStemmer()\n\n# Works fine\nprint(stemmerrslps.stem('intentional'))\nprint(stemmerrslps.stem('books'))\nprint(stemmerrslps.stem('pens'))\nprint(stemmerrslps.stem('goods'))\nprint(stemmerrslps.stem('dives'))\nprint(stemmerrslps.stem('swims'))\n\nprint\n# Doesn't work\nprint(stemmerrslps.stem('caring'))\nprint(stemmerrslps.stem('badly'))\nprint(stemmerrslps.stem('swimming'))\nprint(stemmerrslps.stem('running'))\nprint(stemmerrslps.stem('avoidable'))\nprint(stemmerrslps.stem('vectorization'))\nprint(stemmerrslps.stem('ran'))\nprint(stemmerrslps.stem('tables'))\nprint(stemmerrslps.stem('bottles'))\nprint(stemmerrslps.stem('demonetization'))\nprint(stemmerrslps.stem('amazing'))\nprint(stemmerrslps.stem('happiness'))\nprint(stemmerrslps.stem('laziness'))\nprint(stemmerrslps.stem('unintentional'))\nprint(stemmerrslps.stem('national'))\nprint(stemmerrslps.stem('ambiguous'))\nprint(stemmerrslps.stem('dancing'))\nprint(stemmerrslps.stem('dances'))\nprint(stemmerrslps.stem('focible'))"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "books\npens\ngoods\ndives\nswims\n\nbadly\nswimming\nrunning\ncaring\nvectorization\navoidable\nintentional\nran\ntables\nbottles\ndemonetization\namazing\nhappiness\nlaziness\nunintentional\nnational\nambiguous\ndancing\ndances\nfocible\n"
    }
   ],
   "source": "stemmerisris = ISRIStemmer()\n\nprint(stemmerisris.stem('books'))\nprint(stemmerisris.stem('pens'))\nprint(stemmerisris.stem('goods'))\nprint(stemmerisris.stem('dives'))\nprint(stemmerisris.stem('swims'))\n\nprint\n# Doesn't work\nprint(stemmerisris.stem('badly'))\nprint(stemmerisris.stem('swimming'))\nprint(stemmerisris.stem('running'))\nprint(stemmerisris.stem('caring'))\nprint(stemmerisris.stem('vectorization'))\nprint(stemmerisris.stem('avoidable'))\nprint(stemmerisris.stem('intentional'))\nprint(stemmerisris.stem('ran'))\nprint(stemmerisris.stem('tables'))\nprint(stemmerisris.stem('bottles'))\nprint(stemmerisris.stem('demonetization'))\nprint(stemmerisris.stem('amazing'))\nprint(stemmerisris.stem('happiness'))\nprint(stemmerisris.stem('laziness'))\nprint(stemmerisris.stem('unintentional'))\nprint(stemmerisris.stem('national'))\nprint(stemmerisris.stem('ambiguous'))\nprint(stemmerisris.stem('dancing'))\nprint(stemmerisris.stem('dances'))\nprint(stemmerisris.stem('focible'))"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": "from nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "cactus\nmouse\nrock\nhottest\nam\nwooden\nate\nbrought\nbrightest\ndrove\ngave\nran\nwrote\n"
    }
   ],
   "source": "# Without POS Tagging\n\nprint(lemmatizer.lemmatize(\"cacti\"))\nprint(lemmatizer.lemmatize(\"mice\"))\nprint(lemmatizer.lemmatize(\"rocks\"))\n\nprint(lemmatizer.lemmatize(\"hottest\"))\nprint(lemmatizer.lemmatize(\"am\"))\nprint(lemmatizer.lemmatize(\"wooden\"))\nprint(lemmatizer.lemmatize(\"ate\"))\nprint(lemmatizer.lemmatize(\"brought\"))\nprint(lemmatizer.lemmatize(\"brightest\"))\nprint(lemmatizer.lemmatize(\"drove\"))\nprint(lemmatizer.lemmatize(\"gave\"))\nprint(lemmatizer.lemmatize(\"ran\"))\nprint(lemmatizer.lemmatize(\"wrote\"))\n\n\n"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "hot\nbe\nwooden\neat\nbring\nbright\ndrive\ngive\nrun\nwrite\n"
    }
   ],
   "source": "# With POS Tagging\n\n## Works perfectly fine\n\nprint(lemmatizer.lemmatize(\"hottest\", pos = 'a'))\nprint(lemmatizer.lemmatize(\"am\", pos = 'v'))\nprint(lemmatizer.lemmatize(\"wooden\", pos=\"v\"))\nprint(lemmatizer.lemmatize(\"ate\", pos=\"v\"))\nprint(lemmatizer.lemmatize(\"brought\", pos=\"v\"))\nprint(lemmatizer.lemmatize(\"brightest\", pos=\"a\"))\nprint(lemmatizer.lemmatize(\"drove\", pos=\"v\"))\nprint(lemmatizer.lemmatize(\"gave\", pos=\"v\"))\nprint(lemmatizer.lemmatize(\"ran\", pos=\"v\"))\nprint(lemmatizer.lemmatize(\"wrote\", pos=\"v\"))\n\n# Ran works differently when done pos tagging\n\n"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "natur languag process is a subfield of linguistics, comput science, inform engineering, and artifici intellig concern with the interact between comput and human (natural) languages, in particular how to program comput to process and analyz larg amount of natur languag data.\n"
    }
   ],
   "source": "# Stemming Passages\n\n# PorterStemmer\npara = \"Natural language processing is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\"\nport = [stemmerporter.stem(token) for token in para.split()]\nprint(\" \".join(port))\n\n# Doesn't handle words in a good way."
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Natural language processing is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interaction between computer and human (natural) languages, in particular how to program computer to process and analyze large amount of natural language data.\n"
    }
   ],
   "source": "# Lemmatizer\n\nlemma = [lemmatizer.lemmatize(token) for token in para.split()]\nprint(\" \".join(lemma))\n# Works pretty good with sentences"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "natur languag process is a subfield of linguistics, comput science, inform engineering, and artifici intellig concern with the interact between comput and human (natural) languages, in particular how to program comput to process and analyz larg amount of natur languag data.\n"
    }
   ],
   "source": "# Snowball Stemmer\nsnow = [stemmersnow.stem(token) for token in para.split()]\nprint(\" \".join(snow))\n\n# Works better than porterstemmer"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": "# Count Vectorization\n\nfrom sklearn.feature_extraction.text import CountVectorizer"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[u'and', u'austria', u'both', u'bundesrepublik', u'central', u'constitutionally', u'country', u'deutschland', u'europe', u'federal', u'german', u'germanic', u'germany', u'in', u'is', u'language', u'languages', u'mainly', u'north', u'of', u'official', u'officially', u'one', u'or', u'republic', u'spoken', u'switzerland', u'that', u'the', u'three', u'west', u'western']\n\n[[0 0 0 0 1 0 0 0 1 0 1 1 0 1 2 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n [1 0 0 0 1 1 1 0 0 1 0 0 2 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1]\n [2 1 1 0 0 0 0 0 0 0 1 0 1 0 0 2 1 0 0 3 2 0 1 0 0 0 1 0 1 1 0 0]\n [0 0 0 1 1 0 1 2 1 1 1 0 2 0 0 0 0 0 1 2 0 1 0 1 1 0 0 0 0 0 0 0]]\n\n[u'and austria', u'and one', u'and western', u'austria and', u'both germany', u'bundesrepublik deutschland', u'central and', u'central europe', u'constitutionally the', u'country in', u'country of', u'deutschland country', u'deutschland or', u'federal republic', u'german deutschland', u'german is', u'german language', u'germanic language', u'germany and', u'germany constitutionally', u'germany german', u'germany is', u'germany officially', u'in central', u'is country', u'is mainly', u'is west', u'language of', u'language official', u'language that', u'languages of', u'mainly spoken', u'north central', u'of both', u'of germany', u'of north', u'of switzerland', u'of the', u'official language', u'official languages', u'officially federal', u'one of', u'or bundesrepublik', u'republic of', u'spoken in', u'that is', u'the federal', u'the three', u'three official', u'west germanic']\n\n[[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 0\n  0 0 0 0 0 0 0 0 1 1 0 0 0 1]\n [0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0\n  0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n [1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0\n  1 1 1 1 0 1 0 0 0 0 0 1 1 0]\n [0 0 0 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1\n  0 0 0 0 1 0 1 1 0 0 0 0 0 0]]\n"
    }
   ],
   "source": "corpus = [\n     'German is a West Germanic language that is mainly spoken in Central Europe.',\n     'Germany constitutionally the Federal Republic of Germany is a country in Central and Western..',\n     'German language, official language of both Germany and Austria and one of the three official languages of Switzerland.',\n     'Germany, officially Federal Republic of Germany, German Deutschland or Bundesrepublik Deutschland, country of north-central Europe.']\n\nvectorizer = CountVectorizer()\n\nX = vectorizer.fit_transform(corpus)\n\nprint(vectorizer.get_feature_names())\nprint\n\nprint(X.toarray())\nprint\n\nvectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n\nX2 = vectorizer2.fit_transform(corpus)\n\nprint(vectorizer2.get_feature_names())\nprint\n\nprint(X2.toarray())\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
